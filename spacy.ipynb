{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"The quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>pos_</th>\n",
       "      <th>tag_</th>\n",
       "      <th>dep_</th>\n",
       "      <th>shape_</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>quick</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brown</td>\n",
       "      <td>brown</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fox</td>\n",
       "      <td>fox</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jumps</td>\n",
       "      <td>jump</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>over</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lazy</td>\n",
       "      <td>lazy</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text lemma_   pos_ tag_   dep_ shape_  is_alpha  is_stop\n",
       "0    The    the    DET   DT    det    Xxx      True     True\n",
       "1  quick  quick    ADJ   JJ   amod   xxxx      True    False\n",
       "2  brown  brown    ADJ   JJ   amod   xxxx      True    False\n",
       "3    fox    fox   NOUN   NN  nsubj    xxx      True    False\n",
       "4  jumps   jump   VERB  VBZ   ROOT   xxxx      True    False\n",
       "5   over   over    ADP   IN   prep   xxxx      True     True\n",
       "6    the    the    DET   DT    det    xxx      True     True\n",
       "7   lazy   lazy    ADJ   JJ   amod   xxxx      True    False\n",
       "8    dog    dog   NOUN   NN   pobj    xxx      True    False\n",
       "9      .      .  PUNCT    .  punct      .     False    False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = [[token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "               token.shape_, token.is_alpha, token.is_stop] for token in doc]\n",
    "\n",
    "df = pd.DataFrame(columns=['text', 'lemma_', 'pos_', 'tag_', 'dep_', 'shape_', 'is_alpha', 'is_stop'], \n",
    "                  data=token_list)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'determiner'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('DET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "Case=Nom|Number=Sing|Person=1|PronType=Prs\n",
      "['Prs']\n"
     ]
    }
   ],
   "source": [
    "print(\"Pipeline:\", nlp.pipe_names)\n",
    "doc = nlp(\"I was reading the paper.\")\n",
    "token = doc[0]  # 'I'\n",
    "print(token.morph)\n",
    "print(token.morph.get(\"PronType\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component       Assigns           Requires         Scores        Retokenizes\n",
      "-   -------------   ---------------   --------------   -----------   -----------\n",
      "0   tagger          token.tag                          tag_acc       False      \n",
      "                                                                                \n",
      "1   entity_linker   token.ent_kb_id   doc.ents         nel_micro_f   False      \n",
      "                                      doc.sents        nel_micro_r              \n",
      "                                      token.ent_iob    nel_micro_p              \n",
      "                                      token.ent_type                            \n",
      "\n",
      "\u001b[1m\n",
      "================================ Problems (4) ================================\u001b[0m\n",
      "âš  'entity_linker' requirements not met: doc.ents, doc.sents, token.ent_iob,\n",
      "token.ent_type\n",
      "{'summary': {'tagger': {'assigns': ['token.tag'], 'requires': [], 'scores': ['tag_acc'], 'retokenizes': False}, 'entity_linker': {'assigns': ['token.ent_kb_id'], 'requires': ['doc.ents', 'doc.sents', 'token.ent_iob', 'token.ent_type'], 'scores': ['nel_micro_f', 'nel_micro_r', 'nel_micro_p'], 'retokenizes': False}}, 'problems': {'tagger': [], 'entity_linker': ['doc.ents', 'doc.sents', 'token.ent_iob', 'token.ent_type']}, 'attrs': {'token.ent_type': {'assigns': [], 'requires': ['entity_linker']}, 'doc.ents': {'assigns': [], 'requires': ['entity_linker']}, 'token.tag': {'assigns': ['tagger'], 'requires': []}, 'doc.sents': {'assigns': [], 'requires': ['entity_linker']}, 'token.ent_iob': {'assigns': [], 'requires': ['entity_linker']}, 'token.ent_kb_id': {'assigns': ['entity_linker'], 'requires': []}}}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E109] Component 'tagger' could not be run. Did you forget to call `initialize()`?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1026\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1026\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1028\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:56\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:1670\u001b[0m, in \u001b[0;36mraise_error\u001b[1;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[0;32m   1669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[1;32m-> 1670\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\tagger.pyx:143\u001b[0m, in \u001b[0;36mspacy.pipeline.tagger.Tagger.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39monly the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\with_array.py:32\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Ragged):\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n\u001b[0;32m     33\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Padded):\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\with_array.py:87\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     86\u001b[0m layer: Model[ArrayXd, ArrayXd] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 87\u001b[0m Y, get_dX \u001b[39m=\u001b[39m layer(Xr\u001b[39m.\u001b[39;49mdataXd, is_train)\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYr: Ragged) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Ragged:\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[layer(X, is_train\u001b[39m=\u001b[39;49mis_train) \u001b[39mfor\u001b[39;49;00m layer \u001b[39min\u001b[39;49;00m model\u001b[39m.\u001b[39;49mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Ys[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[layer(X, is_train\u001b[39m=\u001b[39;49mis_train) \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Ys[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mcallback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\layers\\hashembed.py:61\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, ids, is_train)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m     59\u001b[0m     model: Model[Ints1d, OutT], ids: Ints1d, is_train: \u001b[39mbool\u001b[39m\n\u001b[0;32m     60\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 61\u001b[0m     vectors \u001b[39m=\u001b[39m cast(Floats2d, model\u001b[39m.\u001b[39;49mget_param(\u001b[39m\"\u001b[39;49m\u001b[39mE\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     62\u001b[0m     nV \u001b[39m=\u001b[39m vectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\model.py:216\u001b[0m, in \u001b[0;36mModel.get_param\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params\u001b[39m.\u001b[39mhas_param(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid, name):\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for model \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has not been allocated yet.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n\u001b[0;32m    219\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_params\u001b[39m.\u001b[39mget_param(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid, name)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Parameter 'E' for model 'hashembed' has not been allocated yet.\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m nlp\u001b[39m.\u001b[39madd_pipe(\u001b[39m\"\u001b[39m\u001b[39mentity_linker\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(nlp\u001b[39m.\u001b[39manalyze_pipes(pretty\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m----> 8\u001b[0m doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39;49m\u001b[39mThis is a sentence. This is another sentence.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents:\n\u001b[0;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(sent\u001b[39m.\u001b[39mtext)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1029\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1028\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m-> 1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1031\u001b[0m     error_handler(name, proc, [doc], e)\n",
      "\u001b[1;31mValueError\u001b[0m: [E109] Component 'tagger' could not be run. Did you forget to call `initialize()`?"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = spacy.blank(\"en\")  # just the language with no pipeline\n",
    "#nlp.add_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(\"tagger\")\n",
    "nlp.add_pipe(\"entity_linker\")\n",
    "print(nlp.analyze_pipes(pretty=True))\n",
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1004] Missing lemmatizer table(s) found for lemmatizer mode 'rule'. Required tables: ['lemma_rules']. Found: []. Maybe you forgot to call `nlp.initialize()` to load in the data?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m nlp\u001b[39m.\u001b[39madd_pipe(\u001b[39m\"\u001b[39m\u001b[39mlemmatizer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39;49m\u001b[39mThis is a sentence. This is another sentence.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents:\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(sent\u001b[39m.\u001b[39mtext)\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1031\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1031\u001b[0m     error_handler(name, proc, [doc], e)\n\u001b[0;32m   1032\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(doc, Doc):\n\u001b[0;32m   1033\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE005\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, returned_type\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc)))\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:1670\u001b[0m, in \u001b[0;36mraise_error\u001b[1;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[0;32m   1669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[1;32m-> 1670\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1026\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1025\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1026\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1028\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:130\u001b[0m, in \u001b[0;36mLemmatizer.__call__\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m\"\"\"Apply the lemmatizer to one document.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[39mdoc (Doc): The Doc to process.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mDOCS: https://spacy.io/api/lemmatizer#call\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validated:\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_tables(Errors\u001b[39m.\u001b[39;49mE1004)\n\u001b[0;32m    131\u001b[0m error_handler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\asobczak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:173\u001b[0m, in \u001b[0;36mLemmatizer._validate_tables\u001b[1;34m(self, error_message)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m required_tables:\n\u001b[0;32m    172\u001b[0m     \u001b[39mif\u001b[39;00m table \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlookups:\n\u001b[1;32m--> 173\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m             error_message\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    175\u001b[0m                 mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    176\u001b[0m                 tables\u001b[39m=\u001b[39mrequired_tables,\n\u001b[0;32m    177\u001b[0m                 found\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlookups\u001b[39m.\u001b[39mtables,\n\u001b[0;32m    178\u001b[0m             )\n\u001b[0;32m    179\u001b[0m         )\n\u001b[0;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: [E1004] Missing lemmatizer table(s) found for lemmatizer mode 'rule'. Required tables: ['lemma_rules']. Found: []. Maybe you forgot to call `nlp.initialize()` to load in the data?"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe(\"lemmatizer\")\n",
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a35c7b0a2e7b4810aaf3f85419c2d53b-0\" class=\"displacy\" width=\"400\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Hello</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">INTJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">World!</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a35c7b0a2e7b4810aaf3f85419c2d53b-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a35c7b0a2e7b4810aaf3f85419c2d53b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M225.0,91.5 L233.0,79.5 217.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Hello World!\")\n",
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun phrase as adverbial modifier'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('npadvmod')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ca4cf473094cb23e8b3605a86efff78eb15787d4a1786f32a98a841d22af1b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
